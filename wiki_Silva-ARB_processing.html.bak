Some members of the BPC are on the moderated arb-users email list.  Along with lots of other traffic, the moderators send an announcement of updates to the silva database.  The database has aligned 16s sequences from a variety of sources and the updates occur several times a year.   

According to Frank Oliver Gloeckner, the accession number plus start site should be a unique identifier.  This is *almost* true.  There are some duplicates, which seem to represent sequences with alternative alignments.  We need to keep the one with better quality scores. (The few cases where accession id and start are not unique can be resolved by including the stop location).


==Exporting the data from Silva-ARB==

<ol>
<li>Log onto an ARB server using "ssh -X".
Move into the appropriate directory containing latest silva updates (e.g., g454/reftaxonomy/silva/silva_release95)
</li>

<li>Open ARB (type arb on the command line), select SSUParc_95_SILVA_07_07_08.arb, and set the display information as per the table below
(Tree->NDS).  
</li>

Be sure to export in the SAME ORDER as the database tables are in this order. Check both LEAF and GRP. and use Entries 11-20 to add all fields.

{| {{table}}
| align="left" style="background:#f0f0f0;"|'''Field'''
| align="left" style="background:#f0f0f0;"|'''Width'''
| align="left" style="background:#f0f0f0;"|'''Explanation'''
|-
| name||10||ARB-generated id
|-
| acc||16||NCBI accession number
|-
| start||15||start position based on parent sequence (accession)
|-
| stop||15||stop position based on parent sequence (accession)
|-
| full_name||300||description, based on original record
|-
|  (tax_slv)?||400||taxonomy(1)|taxonomic string, from what?
|-
| tax_rdp||400||taxonomic string, based on RDP assessment
|-
| tax_gg||400||taxonomic string, based on GreenGenes assessment
|-
| tax_embl||400||taxonomic string, based on original record
|-
| strain||80||information on cultured strains
|-
| seq_quality_slv||3||silva-generated sequence quality value
|-
| align_quality_slv||3||silva-generated alignment quality value
|-
| pintail_slv||3||silva-generated estimate of chimerism
|}

<li>Select all records (Species->Mark Species->Mark All Species) and 
export the data nodes (*.nds) (File->Export->Export Fields Using NDS)
Be sure to select "Use Tabs for Columns"
</li>

<li>Export the sequence data to a fasta file.  parc95.align.fa or silva95.align.fa
</li>

<li>The fasta file will contain U instead of T, "." for terminal gaps rather than "-", spaces inserted between every 10 bases,
and extra descriptive information on the defline.  
Create a clean fasta file using /bioware/seqinfo/bin/clean_silva_align
</li>

<li>Create a copy of the unaligned sequences </li>

  unalign parc95.align.clean.fa parc95.unalign.fa

<li>Export the Arb tree taxonomy for its domain and phylum.  (THIS STEP IS NOT CLEAR)
Open SSURef_95_SILVA_11_07_08_opt.arb, 
Select visible info name (arb_id) and taxonomy(15), field width(255) for all leaves, 
then export all to nds
</li>
</ol>

==Importing the data to RefSSU==

1.  Rename the current refssu and refssu_align tables using the silva version (refssu_94, refssu_align_94).  
Create empty refssu and refssu_align tables by copying on the structure from the previous tables.

2.  Import the nodes data to refssu

3. Import the clean aligned fasta file into refssu_align (~4 hours):

     fasta2db -g newbpcdb2 -d env454 -i parc95.align.clean.fa -t refssu_align -id arb_id -seq seqssu_align

4.  Import the clean unaligned fasta file into a temp table: refssu_unalign.
      fasta2db -g newbpcdb2 -d env454 -i parc95.unalign.fa -t refssu_unalign -id arb_id -seq sequence -len seqlength

5.  Run RDP

     /usr/local/www/vamps/docs/apps/rdp silva111.unalign.fa silva111.rdp
     or
     java -Xmx1g -jar /bioware/rdp_classifier_2.6/dist/classifier.jar classify -o silva115_rdp26.res -f fixrank silva115_unalign_26.fa
     
and import

     rdp2taxonomy -b 80 silva111.rdp > silva111.rdp.tax
     mysql -h newbpcdb2 env454 -e 'LOAD DATA LOCAL INFILE "silva111.rdp.tax" INTO TABLE refssu111_rdp (arb_id, taxrdp, boots, rank);'

6. Update table information:

      update refssu as r join refssu_unalign as ru using(arb_id)
      set r.sequence = ru.sequence, r.seqlength = ru.seqlength      
      
      update refssu
      set stop = (`start` + seqlength -1) 
      
      update refssu
      set refssu_id = concat_ws('_', accession_id, start, stop)
      
      update refssu as r join refssu_strain as rs using(arb_id)
      set r.culturestrain = rs.strain 
      where rs.strain != <nowiki>''</nowiki>
      
      update refssu as r join refssu_typestrain as rt using(arb_id)
      set r.typestrain = 1 
      where rt.strain != <nowiki>''</nowiki>

7.  Incorporate taxonomic information

      a.  '''RDP''' -- double-check that all the RDP values have look-ups to MBL in tax_rdp.  
                          add entries to tax_rdp for any new values
    
     select distinctrow r.taxonomy, xr.mbl
     from refssu_rdp as r join tax_rdp as xr using(taxonomy)
     where r.taxonomy != <nowiki>''</nowiki>
     and xr.mbl = <nowiki>''</nowiki>
    
     update refssu as r, refssu_rdp as rr, tax_rdp as xr
     set r.tax_rdp = xr.mbl, r.tax_rdp_boot = rr.bootvalues
     where r.arb_id = rr.arb_id AND rr.taxonomy = xr.taxonomy

      b.  '''Hugenholtz''' -- the slvtax_gg field in refssu is the Hugenholtz taxonomy.  
            This may have trailing semicolons.  Clean them out so the join works:
      
       update refssu
       set taxslv_gg = substring(taxslv_gg, 1, length(taxslv_gg) - 1) 
       where taxslv_gg like '%;'
       
       update refssu as r, tax_hugenholtz as xh
       set r.tax_hugenholtz = xh.mbl
       where concat(xh.taxonomy,';') = r.taxslv_gg
       and mbl != <nowiki>''</nowiki>

      c. '''Entrez Genomes''' -- should see if there are new entries to catalog (add to tax_entrezgenome)
      update refssu as r join tax_entrezgenome as x on(r.accession_id = substring_index(x.accession_id, '.', 1) ) 
      set r.tax_entrzg = x.mbl
     
      To look for additional taxa go to: http://www.ncbi.nlm.nih.gov/sites/genome
       copy the Bacteria and then the Archaeal values, paste into Excel (to get the fields), export to text
       load into new table and handle the data from there.

       d.  '''EMBL''' -- need to complete the lookup table tax_embl, needs a lot more work
            not currently using this for taxonomy, although will need it for Euk taxa.

       e.  '''Silva Full name''' -- need to complete the lookup table tax_silva_fullname
       update refssu as r join tax_silva_fullname as x using(silva_fullname )
       set tax_fullname = x.mbl

       f.  '''Silva Taxonomy'''  --  trust the domain;phylum over RDP, but not full taxonomy 
            ''Need to complete the refssu_silvatax -- still missing many taxa''
       
       first convert the nds to a first cut taxonomy and then pull into the database.
       clean_silvatax taxonomy15.nds > silvatax.txt
       mysql> load data local infile 'silvatax.txt' into table refssu_silvatax
    
       complete and update the tax_silva_taxonomy lookup table from silva taxonomy to mbl
       (initially created by: mysql> insert into tax_silva_taxonomy select distinct taxonomy,"","" from refssu_silvatax order by taxonomy;)
    
      g.  '''Silva DomainPhyla''' - grab valid d;p from silva_taxonomy or from silva_fullname

      # update the tax_silva and tax_silvadp fields in refssu
       update refssu as r, tax_silva_taxonomy as xs, refssu_silvatax as rx
       set r.tax_silva = xs.mbl, r.tax_silvadp = domainphylum
       where r.arb_id = rx.arb_id and rx.taxonomy = xs.taxonomy

       # if haven't completed the silva taxonomy field, but the tax_fullname matches an mbl.dp, use it.
       update refssu as r join tax_mbl as xm on (substring_index(tax_fullname, ';',2) = xm.taxonomy)
       set tax_silvadp = substring_index(tax_fullname, ';',2)
       where tax_silvadp = <nowiki>''</nowiki>
      
      h.  '''Other Sources''' -- like SAR11
      
      #create the refssu_othersource table that can be used to join with arb_id or accession_id, then update other taxa fields
      update refssu_sar11 as rs join refssu as r using(accession_id) 
      set tax_other = rs.taxonomy, 
      r.tax_othersrc = rs.source
    
8.  OLD!!  used to use $seq/import_silva_updates, but now the process has changed too much.  Do it by hand instead.

9.  Flag low-quality sequences in refssu -- use delete_lowqual.sql in silva_release95/
      UPDATE refssu set deleted=1, delete_reason='Low Quality Sequence' where deleted=0 and silva_seq_qual <= 50;
      UPDATE refssu set deleted=1, delete_reason='Chimera' where deleted=0 and silva_pintail_score <= 50;
      UPDATE refssu set deleted=1, delete_reason='Low Quality Alignment' where deleted=0 and silva_align_qual <= 75;
      UPDATE refssu set deleted=1, delete_reason='Sequence Length < 500' where deleted=0 and length(sequence) < 500;

10.  Remove duplicate sequences 'Duplicate seq16s' 
          update ref16s as r,
          (select seq16s, count(alt_local_gi) as seqcnt, min(alt_local_gi) as minAlt
          from ref16s
          where deleted=0
          group by seq16s
          having seqcnt > 1) as d
          set r.deleted=1, 
          r.delete_reason='Duplicate seq16s'
          where r.seq16s=d.seq16s
          and r.deleted=0
          and r.alt_local_gi != d.minAlt

==Updating the taxonomy of the sequences==

1.  Update RDP  using run_rdp in $g454/reftaxonomy/rdp/updateRef16s/release7.8cyano/
       select all new sequences that are not deleted or all sequences not deleted if you are 
          updating with a new RDP training set.
           
          # Export the sequences to fasta
          db2fasta -d env454 -id alt_local_gi -seq seq16s -o 20080221.fa 
                           -sql "SELECT alt_local_gi, seq16s from ref16s where deleted=0"
     
          # Run rdp on the sequences
          rdp 20080221.fa 2080221.rdp
          
          # Convert the rdp output format to the tax and boot strings we use
          rdp2ref16s 20080221.rdp > 20080221.rdp.out1  
                 (NB: this is instead of rdp_checker with new rdp values -- see note below)
          
          # if tax doesn't go down to genus, fill in the necessary ";"s. 
          #  These are primarily the *genera_incertae_sedis, and Cyanobacteria (we are including Chrococcales)
          findNotGenus 20080221.rdp.out1 > 20080221.rdp.out2
         
          # There are some subclasses and suborders included in RDP, strip these out
          removeSubRanks 20080221.rdp.out2 > 20080221.rdp.out3
          
          # Import the data into the database
          importRDP -ref ref16s 20080221.rdp.out2
 
    Note:  depending on the status of Bergey.pm either run rdpchecker and rdpchecker2ref16s
                rdp_checker -b 0 -tagrdp -log 20080221.rdp.log 20080221.rdp > 20080221.rpd.out
                rdpchecker2ref16s -ref ref16s 20080221.rdp.out
    

2.  Update the Hugenholtz taxonomy from greengenes
      
      download the latest file from http://greengenes.lbl.gov/Download/Sequence_Data/Greengenes_format
      
      use Hugenholtz where there is only one value, not conflicting values, see readme in reftaxonomy/greengenes/2008Jan13


3.  Update from representative genomes in NCBI  (g454/reftaxonomy/rep_genomes/readme)
   
      download the genome accession IDs and taxonomy from Entrez (microbial genomes)
     
      clean the output file (as per the readme)
     
      add the superkingdom--->family to the genus;species;strain 
      using addPreGenus1_RDP and addPreGenus2_NCBI  
      addPreGenus1_RDP genometax.txt > genometax2.txt
      addPreGenus2_NCBI genometax2.txt > genometax3.txt
      
      Import the data into the database -- 
      !!!!!!!  check that the if (accession already had other_taxonomy is working)
      importGenomes genometax3.txt

4.  Insert other taxonomy sources as appropriate
    
     other sources for specific accession IDs should be added by hand as appropriate.
     g454/reftaxonomy/othersources includes a directory for each other source and instructions as to what they were.

5.  Merge the alternate taxonomies into the taxonomy and taxonomy_source fields:
    
      # Reset the taxonomy and taxonomy_source fields
      update refssu set taxonomy = '', taxonomy_source = ''
  
     # update in order of preference:
   
       <pre>update refssu set taxonomy = tax_entrzg, taxonomy_source = 'Entrez Genome' where taxonomy = "" and tax_entrzg != ""; </pre>
       update refssu set taxonomy = tax_hugenholtz, taxonomy_source = 'Hugenholtz' where taxonomy = "" and tax_hugenholtz != "";
       update refssu set taxonomy = tax_other, taxonomy_source = tax_othersrc where taxonomy = "" and tax_other != "";
       update refssu set taxonomy = tax_fullname, taxonomy_source = 'Cultured Silva fullname'
                    where taxonomy = '' and tax_fullname != "" and culturestrain != "";
       update refssu set taxonomy = tax_silvadp, taxonomy_source = 'Silva domain;phylum' where taxonomy = "" and tax_silvadp != "";
        
       update refssu set taxonomy = tax_rdp, taxonomy_source = 'RDP'
              where taxonomy_source = "Silva domain;phylum" and tax_rdp != ""
              AND taxonomy like '%;%' and substring_index(tax_rdp,';', 2) = taxonomy;
      
       update refssu  set taxonomy = tax_rdp, taxonomy_source = 'RDP'
              where taxonomy_source = "Silva domain;phylum" and tax_rdp != ""
              AND taxonomy not like '%;%' and substring_index(tax_rdp,';', 1) = taxonomy;
        
       update refssu set taxonomy = tax_rdp, taxonomy_source = 'RDP' where taxonomy = "" and tax_rdp != "";
       update refssu set taxonomy = tax_silva, taxonomy_source = 'Silva taxonomy' where taxonomy = "" and tax_silva != ""; #no results
       update refssu set taxonomy = taxslv_embl, taxonomy_source = 'Raw EMBL taxonomy' where taxonomy = "" 
                   and taxslv_embl != "" and taxslv_embl like 'Euk%';

6.  Taxonomy cleanup
       # remove trailing semicolons:
       update refssu set taxonomy = substring(taxonomy, 1, length(taxonomy) -1 ) where taxonomy like '%;'
       update refssu set taxonomy = 'NA', taxonomy_source = 'No available taxonomy' where taxonomy = "";
       update refssu set taxonomy = replace(taxonomy, 'Eukaryota', 'Eukarya') where taxonomy like 'Eukaryota%'

7.  Set the Rank field
update refssu set rank = 'NA' where taxonomy = 'NA'       
update refssu set rank = 'domain' where taxonomy not like '%;%' and taxonomy != 'NA'
update refssu set rank = 'strain' where taxonomy like '%;%;%;%;%;%;%;%'
update refssu set rank = 'species' where taxonomy like '%;%;%;%;%;%;%' and rank = ''
update refssu set rank = 'genus' where taxonomy like '%;%;%;%;%;%' and rank = ''
update refssu set rank = 'family' where taxonomy like '%;%;%;%;%' and rank = ''
update refssu set rank = 'order' where taxonomy like '%;%;%;%' and rank = ''
update refssu set rank = 'class' where taxonomy like '%;%;%' and rank = ''
update refssu set rank = 'phylum' where taxonomy like '%;%' and rank = ''

==Exporting new variable regions as reference databases==



Find the location of the primers in the silva version(s).
     # get the list of primers and their sequences for each variable region
      select * from primers;
      
      #run findprimers for the new silva version for each primer.
      # The findprimers results will go into ref16s_regions   (SUE: What is ref16s_regions? a table? a script?)
      findprimers -domain Bacteria -seq AGGTGGTGCATGGCTGTCG 
      start=13335, end=13375
      Primer: A-G-G-T--G-G--TG---CA-TG--G---CT--G--TC-G
      
      # Populate the variable region into refssu_primerlocs
      # since this isn't incorporated yet with findprimers, I create an sql script and then source the script.
      insert into refssu_primerlocs values ('<primer name>', '<region>', <silva version>, <start>, <end>, '<direction>');
     eg:  insert into refssu_primerlocs values ('958F', 'v6', 93, 12189, 12227, 'F');

Run the '''refssu2hvr''' script, which calculates trim coordinates from refssu_primerlocs,
then pulls up the longs, trims them, tests the new sequence for length and the presence of Ns, 
and inserts them into an output ref table (e.g., refhvr_v6).  Then it updates the empty local_gi
field to assign the lowest alt_local_gi to the local_gi for each set of duplicate v6 sequences.

   cd to $g454/blastdbs and edit the existing run_refssu2hvr script to accommodate the new region.

''To support this variable region extraction, the refssu_primerlocs table must contain'' 
''data for each region -- the forward and reverse primer for each domain and the ''
''coordinates of the primer itself (not the trimmed sequence) along the refssu_align.''

The script uses the following SQL for the trimming and quality testing:
    INSERT INTO $vTable (refssu_id, taxonomy, taxon_source, rdp_boot, domain, sequence) 
    SELECT r.refssu_id, taxonomy, taxonomy_source, tax_rdp_boot, substring_index(taxonomy, ';', 1), 
    replace(substring(a.sequence, ?, ?), '-', '') as hvrsequence
    FROM $refTable as r join $alignTable as a using(arb_id)
    WHERE deleted=0 AND substring_index(taxonomy, ';', 1) = ? 
    AND replace(substring(a.sequence,1,?), '-', '') != '' "
    HAVING length(hvrsequence) >= 50 AND hvrsequence not like '%N%'

***INSERTING NEW HVR IDs************
**  1) Need to maintain existing RefHVR_ids. 
     a) copy in the existing refssu_ids -- 
         update refhvr_v6 as n join refhvr_v6_20100429 as o using(refssu_id)  set n.refhvr_id = o.refhvr_id

     b) remove any refhvr_ids that now have multiple V6s (the underlying sequences changed)
         select refhvr_id, count(distinct sequence) as cnt
         from refhvr_v6 
         where refhvr_id != ''
         group by refhvr_id
         having cnt > 1

        Just copied and pasted the small number into 
           update refhvr_v6 set refhvr_id = '' where refhvr_id in ('v6_AB687','v6_AF230','v6_AF718','v6_BT177','v6_BT262','v6_BT662','v6_CJ107','v6_CS352')
  
      c) Remove any refhvr_ids that are both assigned to the same sequence:
           select sequence, count(distinct refhvr_id) as cnt, group_concat(distinct refhvr_id order by refhvr_id separator ',') as refs
           from refhvr_v6 where refhvr_id != '' group by sequence having cnt > 1
  
          Copy and paste the refhvr_id's as in b) above.
    
       d) TEST THIS ONE AGAIN!!!  Just in case...  it works because you already resolved seqs with multiple refhvr_ids.
            Add old refhvr_id to new refssu_ids that have the same V6 tag as an existing V6 with an refhvr_id:
              update refhvr_v6 as r join
              (select sequence, min(refhvr_id) = max(refhvr_id) as same, min(refhvr_id) as minid, max(refhvr_id) as maxid , count(distinct refhvr_id)
              from refhvr_v6 group by sequence having same = 0) as t1
              using(sequence)
              set r.refhvr_id = t1.maxid
              where r.refhvr_id = ''

      e) determine the last id: 
             select max(refhvr_id) from refhvr_v6 
           and the number of IDs 
              select count(distinct refhvr_id) from refhvr_v6_previous
           Test the number in the @a statement at the bottom and use it for inserting the new refhvr_ids.
  
Then it assigns a refhvr_id for each sequence, using the an alphanumeric id (AA001 ...) 

THIS IS FOR INSERTING IDS IN A BRAND NEW REFHVR TABLE:
*** For some reason this is not executing correctly and must be run by hand!! 
      (I had to run it in a terminal rather than in Navicat or Sequal Pro: mysql -h jbpcdb < txtfile.txt > log.out)***
     set @a=0;
     update refhvr_v6 as rv join
     (select concat('v6_', 
     char( floor(( (@a:=@a+1) - mod(@a, 1000)) / 1000 / 26) + 65),
     char(mod(((@a - mod(@a, 1000)) / 1000), 26) + 65),
     lpad(mod(@a,1000),3,0)) as refhvr_id, 
     sequence
     from (select sequence, count(*) as seqcnt from refhvr_v6 group by sequence) as t1 ) as t2
     using(sequence)
     set rv.refhvr_id = t2.refhvr_id
  
    THIS IS FOR UPDATING APPENDED REFHVR TABLES - determine the correct @a starting point.
    set @a= 77054;
    update refhvr_v6 as rv join
    (select concat('v6_', 
    char( floor(( (@a:=@a+1) - mod(@a, 1000)) / 1000 / 26) + 65),
    char(mod(((@a - mod(@a, 1000)) / 1000), 26) + 65),
    lpad(mod(@a,1000),3,0)) as refhvr_id, 
    sequence
    from (select sequence, count(*) as seqcnt from refhvr_v6 where refhvr_id = '' group by sequence) as t1 ) as t2
    using(sequence)
    set rv.refhvr_id = t2.refhvr_id
    where rv.refhvr_id = ''

==Exporting variable regions==

To Export a fasta file for GAST
     1. Move to $g454/blastdbs directory
     
     2.  edit run_db2fasta_otherrefs, and change the commented lines 
           to run only your updated reference set;
      
           Or, add a new db2fasta line for the new reference set modeled from 
           the existing reference sets (e.g., V6 or V3V5)

To Create a BLAST database
Export each blast database separately using the $seq script export_ref16s

     1.  Move to $g454/blastdbs directory
     
     2.  run refssu2blastdb for each database
           refssu2blastdb -arc -bac -euk -r v6
           refssu2blastdb -arc -bac -euk -r v9
     
     3.  Run formatdb on each new fasta file
          foreach i (refv6_arc refv6_bac refv6_euk)
          run_formatdb $i
          end
       
     4.  Report new $g454/blastdbs/ fasta files to David for inclusion in blast updates
